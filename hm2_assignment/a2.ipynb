{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "Instructions: Implement both PG and an evolutionary algorithm to solve the Open AI Gym Lunar Lander problem, and then apply it to my area of choice, which is chess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to do some setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "# Set the device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"gpu\" # üßÆ\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = \"mps\" # üß†\n",
    "else:\n",
    "    device = \"cpu\" # ü•∫\n",
    "    \n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to write the code for our Policy Gradient function with a baseline (taken from REINFORCE). I'm going to use PyTorch as my neural network library (I want to try JAX, but this is the more practical choice for me at the moment. Exploration-Exploitation tradeoff ü§∑‚Äç‚ôÇÔ∏è).\n",
    "\n",
    "I'm going to start with a basic feed forward net for both the network that chooses the policy and the network that learns states' values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the policy network for choosing actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class PolicyChoice(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PolicyChoice, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.policy = nn.Sequential(\n",
    "            nn.Linear(8, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 4), # TODO: try reducing to one hidden layer if learning proves initially dificult\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 4),\n",
    "            nn.Softmax(dim=0) # log softmax for a nice interpretation as probabilities of choosing actions\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        probs = self.policy(x)\n",
    "        return probs\n",
    "\n",
    "policy_model = PolicyChoice().to(device)\n",
    "policy_adam = torch.optim.Adam(policy_model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our loss function for the policy network, we want to adjust just the parameters with the primary aim of affecting the probability of taking the action that we took on that time step. If the return of the resulting state is better than expected, we want to increase it proportionally. If it is less than expected, we want to decrease it proportionally. Thus, we multiply the gradient of the parameter weights w.r.t. the taken action's probability by the difference of the return for that state-action pair.\n",
    "\n",
    "Importantly, there is an extra factor however that we must consider; when we decide that we want to take the gradient of the parameters w.r.t. a specific action's return, the policy expectancy must be multiplied by the specific action's likelihood to determine the value it contributes to the policy. Thus, we end up with the gradient of the action's probability conditioned on the state and parameters. \n",
    "\n",
    "Thus, the general concept of loss to backpropogate in the REINFORCE algorithm is:\n",
    "\n",
    "\n",
    "$\\Large (G_t - \\hat{\\upsilon}) \\frac{\\nabla\\pi(A_t|S_t, \\theta)}{\\pi(A_t|S_t, \\theta)}$\n",
    "\n",
    "This can be expressed as:\n",
    "\n",
    "$\\Large (G_t - \\hat{\\upsilon}) \\nabla \\ln{\\pi(A_t|S_t, \\theta)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below just worries about the loss and not the gradient, as PyTorch provides autograd differentiation behind the scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: pretty sure I need to change this have all 4 softmax outputs\n",
    "def policy_loss(prob, state_util_difference):\n",
    "    nll_loss = nn.NLLLoss()\n",
    "    return nll_loss(prob, torch.ones(1)) * state_util_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the network for approximating state utililities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateUtility(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StateUtility, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.state_utility = nn.Sequential(\n",
    "            nn.Linear(8, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 4), # TODO: try reducing to one hidden layer if learning proves initially dificult\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 1), # output a tensor of a scalar value\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        state_utility = self.state_utility(x)\n",
    "        return state_utility\n",
    "\n",
    "state_util_model = StateUtility().to(device)\n",
    "state_util_adam = torch.optim.Adam(state_util_model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the state utilities network, we just use L1 loss with the gradients of W with respect to state utility.\n",
    "\n",
    "$\\Large (G_t - \\hat{\\upsilon}(S_t, W)) \\nabla \\hat{\\upsilon}(S_t, W)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like above, the code below just worries about the loss and not the gradient, as PyTorch provides autograd differntiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_util_loss(calculated_state_value, episode_state_value):\n",
    "    # the overall state value is the input, and the individual state value is our target\n",
    "    l1_loss = nn.L1Loss()\n",
    "    return l1_loss(calculated_state_value, episode_state_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = .99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the Lunar Lander environment now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6941.991863250732, 16199.033813476562, 14587.366539001465, 17708.747940063477, 1813.0881671905518, 11828.75845336914, 3936.683624267578, 5558.287757873535, 8201.771430969238, 7016.337368011475, 1721.964900970459, 1753.5125560760498, 2301.5042877197266, 613.7211799621582, 533.0879364013672, 6485.171836853027, 650.1154403686523, 10026.791114807129, 1170.4592094421387, 2693.27001953125, 6969.311126708984, 2133.174362182617, 17417.772270202637, 2391.0910873413086, 3139.4989891052246, 8991.500480651855, 10585.202880859375, 11633.80337524414, 5597.613437652588, 6394.007350921631, 2481.911632537842, 2001.418025970459, 1314.5760803222656, 732.0543823242188, 8012.825832366943, 5088.1151695251465, 1573.9752311706543, 1295.7779731750488, 1385.4859352111816, 971.548168182373, 1410.4799728393555, 550.0129508972168, 24082.834175109863, 2004.9600067138672, 8964.507669448853, 5144.946460723877, 4546.897125244141, 2693.2973861694336, 5437.583400726318, 743.7057952880859, 2118.2358016967773, 2147.3611030578613, 2103.7823905944824, 5417.0730056762695, 765.3379287719727, 5967.742393493652, 1796.4755592346191, 2640.0365619659424, 721.8429756164551, 994.6375694274902, 300.72665786743164, 1666.2530708312988, 7100.807487487793, 4093.43705368042, 5736.96150970459, 1924.3537979125977, 5450.993011474609, 3230.2476348876953, 7286.169380187988, 9146.198207855225, 7591.907112121582, 1858.0078239440918, 2068.421287536621, 3706.028621673584, 703.7914505004883, 2792.8442192077637, 3157.4030265808105, 574.6299896240234, 5078.8269119262695, 2103.2472915649414, 1150.3455123901367, 6389.105545043945, 1012.9762420654297, 1225.2705459594727, 1237.9863662719727, 7059.823318481445, 6608.527290344238, 1690.0830154418945, 766.2026901245117, 11959.840713500977, 3902.1311264038086, 12449.52416229248, 5073.9516525268555, 3649.3936614990234, 10369.4584274292, 4179.859546661377, 4674.848587036133, 8048.809860229492, 2603.604537963867, 2878.8205490112305, 7919.115741729736, 11680.71590423584, 1102.0801467895508, 10825.377220153809, 2363.019359588623, 2786.288246154785, 2406.2349853515625, 5978.685752868652, 3301.8834533691406, 2358.8860206604004, 2278.5169677734375, 7266.069149017334, 6594.568656921387, 2475.409366607666, 9879.469436645508, 3444.7532272338867, 5565.204452514648, 5083.5635986328125, 3375.5679473876953, 1484.7700080871582, 12036.978443145752, 6020.710300445557, 2720.2889556884766, 1393.5251998901367, 12742.623588562012, 648.3246269226074, 1558.8394012451172, 1157.6164474487305, 5882.256690979004, 7024.700813293457, 4873.3414306640625, 4156.314910888672, 2973.540500640869, 8126.09317779541, 4417.309211730957, 8834.577941894531, 3671.058563232422, 4068.9588470458984, 2121.7047729492188, 2478.249340057373, 2329.2831115722656, 9043.22152709961, 2981.0787048339844, 2248.341407775879, 1901.8922996520996, 862.8994598388672, 2434.0620613098145, 5847.193672180176, 2316.556224822998, 14658.247367858887, 6961.06876373291, 5173.919021606445, 2815.7548446655273, 4006.1201934814453, 3893.749668121338, 6391.480400085449, 6464.919387817383, 6181.904487609863, 9682.395751953125, 6648.706405639648, 1253.636604309082, 3199.269016265869, 3708.14554977417, 2013.6010780334473, 1771.3542137145996, 1973.7711868286133, 14703.178123474121, 2769.3356170654297, 7946.727722167969, 2152.423765182495, 1484.4885520935059, 2386.439037322998, 3795.709400177002, 628.127082824707, 7856.133136749268, 2234.3163452148438, 4012.2579193115234, 2756.8068351745605, 8286.676704406738, 1898.1322937011719, 18984.59152984619, 1839.0673294067383, 8174.693168640137, 1190.5290756225586, 5291.931640625, 3929.6998977661133, 3621.2321605682373, 2975.669013977051, 5248.015907287598, 3539.222255706787, 1888.8874893188477, 668.0267105102539, 1516.2865715026855, 592.8390197753906, 1827.323387145996, 2004.1134567260742, 1953.4127731323242, 1437.9127349853516, 2223.141975402832, 5058.804725646973, 1381.5250778198242, 10802.62688446045, 1335.5100479125977, 3244.1941146850586, 4556.631187438965, 4545.824367523193, 8777.662033081055, 3376.9102478027344, 2665.0150718688965, 2458.6030235290527, 1887.184425354004, 7582.330749511719, 1041.8540802001953, 3203.605365753174, 5544.003128051758, 6611.5158767700195, 9057.743896484375, 4017.6382217407227, 2370.3964920043945, 4103.968788146973, 1181.1282272338867, 3194.447841644287, 4468.135082244873, 2476.2514362335205, 1241.3484535217285, 2670.8632583618164, 2620.9253425598145, 1971.8252410888672, 1954.0254440307617, 5243.212863922119, 7864.232513427734, 1122.4524192810059, 3932.8347396850586, 1517.8753967285156, 3865.287696838379, 6899.986656188965, 5501.429153442383, 2042.509506225586, 895.3909072875977, 1895.7558326721191, 9135.092315673828, 1813.7365493774414, 3892.7035789489746, 2780.3555221557617, 1609.2740859985352, 1141.0523376464844, 2011.9880752563477, 3570.7425689697266, 2447.5660438537598, 4868.9581298828125, 7391.457717895508, 316.1130065917969, 3869.4789505004883, 1880.2238426208496, 4975.545791625977, 1837.9989700317383, 3271.816879272461, 6216.869125366211, 1124.445167541504, 3412.2456665039062, 669.46875, 1593.3840866088867, 1543.7493858337402, 6558.835487365723, 959.0874137878418, 8026.747467041016, 4666.967189788818, 8198.369430541992, 1708.8946418762207, 1993.7558555603027, 3352.4790382385254, 670.7145385742188, 2352.4102840423584, 991.4719944000244, 836.3221778869629, 4921.149200439453, 5663.633819580078, 1254.9554481506348, 4492.182968139648, 6539.285446166992, 3300.0642127990723, 12024.497207641602, 2486.1185607910156, 3289.3629150390625, 6869.197052001953, 5350.249809265137, 4996.322319030762, 4324.816864013672, 1928.1704406738281, 5676.0908279418945, 3692.5093154907227, 808.7598876953125, 5566.193023681641, 2813.4882583618164, 2409.2166175842285, 993.8950424194336, 9568.277755737305, 9738.19654083252, 5351.0509033203125, 1593.4502868652344, 6916.505800247192, 6778.095367431641, 6220.6669845581055, 1135.3151893615723, 4619.243560791016, 4422.480369567871, 1590.9094848632812, 1673.339729309082, 2408.6035766601562, 10136.472831726074, 5392.1679763793945, 799.4360733032227, 3547.5583419799805, 7810.40701675415, 6787.640491485596, 687.2364768981934, 4323.226295471191, 3284.1289138793945, 1068.684066772461, 2723.0503845214844, 2191.93701171875, 760.3241271972656, 3071.351432800293, 7355.599098205566, 5731.395492553711, 2103.7942962646484, 2880.3373374938965, 2587.1463317871094, 3713.5224809646606, 2002.471035003662, 2418.8454818725586, 2184.589912414551, 2629.1535263061523, 2711.256523132324, 3103.233627319336, 1925.788345336914, 2247.6965141296387, 2149.179733276367, 12856.249710083008, 2853.36279296875, 2648.5294036865234, 8634.981948852539, 3740.041702270508, 2981.5027465820312, 4225.679382324219, 26492.193782806396, 2121.6743774414062, 7099.095184326172, 7339.311996459961, 2856.748264312744, 7105.014514923096, 5698.159439086914, 1714.2865447998047, 9412.108451843262, 2801.8583374023438, 2749.8638648986816, 487.63622283935547, 4318.943794250488, 1703.3950462341309, 2156.0087890625, 5370.653324127197, 6549.530967712402, 1964.7136268615723, 1493.4419860839844, 788.8664970397949, 1822.9401817321777, 2436.7489280700684, 7030.245725631714, 9606.447746276855, 8819.18872833252, 1809.8685684204102, 2052.0875129699707, 2312.795883178711, 821.1382255554199, 927.8246726989746, 4239.093132019043, 5623.282032012939, 5787.176452636719, 6178.2729415893555, 4566.691383361816, 884.4944152832031, 1486.2200088500977, 5621.207145690918, 4828.194038391113, 3988.585662841797, 1151.4099617004395, 2975.8028926849365, 1842.7194805145264, 5515.656929016113, 1910.7690925598145, 16317.884384155273, 1644.6933288574219, 5256.209091186523, 888.4887466430664, 2261.647548675537, 4393.757312774658, 3781.580976486206, 930.2669143676758, 4263.315277099609, 1312.7896347045898, 2709.3367919921875, 4132.935012817383, 8028.008018493652, 4175.373641967773, 2936.521459579468, 6435.778938293457, 4538.6206130981445, 11449.53182220459, 9479.097499847412, 2016.5862007141113, 1975.6854858398438, 788.0487060546875, 1408.3099517822266, 3521.100685119629, 7781.9709548950195, 1107.9322357177734, 8176.703977584839, 757.7066955566406, 5120.202377319336, 1515.7769355773926, 2881.8486137390137, 15050.675365447998, 694.3909111022949, 1623.8438777923584, 3655.984691619873, 4418.476535797119, 1984.8518409729004, 1256.7316246032715, 1597.8766899108887, 1902.7469387054443, 7173.684061050415, 1525.0986194610596, 3907.125431060791, 3472.2058296203613, 8117.212944030762, 413.75829315185547, 1753.7148361206055, 1139.21919631958, 488.46894454956055, 1448.3657112121582, 3359.667304992676, 5497.2608642578125, 2405.548957824707, 1649.2572555541992, 10509.060836791992, 1826.9967575073242, 2108.2132606506348, 2460.817953109741, 838.5191879272461, 3821.892364501953, 3391.2091751098633, 696.8403472900391, 1064.3113441467285, 3321.942943572998, 1537.1381759643555, 793.4717636108398, 1769.5859451293945, 994.5005683898926, 3459.541343688965, 2277.389247894287, 4092.332769393921, 1302.5989227294922, 27787.005850315094, 1332.8504161834717, 14079.380786895752, 1074.8691177368164, 5917.952705383301, 3774.48565864563, 9681.322242736816, 4332.91618347168, 2708.9847869873047, 1849.0726776123047, 4867.192329406738, 2167.4642333984375, 2216.4146728515625, 3418.220443725586, 3318.5426712036133, 2061.3697624206543, 2786.5416717529297, 918.1998291015625, 5773.732856750488, 5120.175304412842, 3814.4683799743652, 2207.762044906616, 3177.625804901123, 2750.730854034424, 5489.445030212402, 7560.712837219238, 2751.690643310547, 2030.7613983154297, 1803.2200393676758, 4830.059661865234, 2726.227643966675, 4054.244094848633, 3015.649948120117, 2343.3247604370117, 545.4476089477539, 2114.406074523926, 6663.419860839844, 8333.332967758179, 5996.942268371582, 2421.6481895446777, 1437.9854888916016, 6357.847831726074, 11965.551452636719, 3345.9714431762695, 1802.457649230957, 2218.508644104004, 11454.833152770996, 826.0569305419922, 4494.908271789551, 3649.436305999756, 1664.8128967285156, 2829.410388946533, 10179.233787536621, 6870.225811004639, 1091.4796600341797, 18482.960647583008, 7961.261497497559, 1611.2595977783203, 4780.776039123535, 851.9115905761719, 5065.977108001709, 1306.8530349731445, 2063.677734375, 782.7771911621094, 9935.207916259766, 1407.6140594482422, 4559.418006896973, 2999.4208602905273, 3405.8009605407715, 4478.581287384033, 1448.5175437927246, 4086.210765838623, 2813.4226264953613, 1049.9886322021484, 1299.199821472168, 2206.9483528137207, 1835.6374855041504, 1626.746322631836, 1338.0126609802246, 2772.083183288574, 2870.047218322754, 1737.8154525756836, 1654.4833011627197, 6043.177879333496, 1101.9787826538086, 1261.5670623779297, 1984.7584438323975, 4203.566883087158, 1702.241870880127, 1550.0334777832031, 3188.342758178711, 3808.905990600586, 3568.821922302246, 1668.211296081543, 2532.071144104004, 10688.242126464844, 7283.497131347656, 3017.1092376708984, 3287.355224609375, 650.7942123413086, 3827.2515258789062, 1493.2466888427734, 2244.8840255737305, 1074.9924507141113, 1616.1031036376953, 4415.913925170898, 2962.1194190979004, 922.6181411743164, 2951.1367797851562, 690.6677398681641, 2904.176254272461, 12151.408508300781, 1928.1867980957031, 7051.290588378906, 8653.479835510254, 1469.5941429138184, 2339.9054946899414, 1596.8180351257324, 5128.228050231934, 7114.324760437012, 846.6963806152344, 1015.8725433349609, 595.9298095703125, 1479.1987495422363, 10904.104927062988, 1341.1226234436035, 3705.8038902282715, 746.1115341186523, 5286.51163482666, 4466.09538269043, 9301.26953125, 2009.2225189208984, 1503.4947891235352, 3067.7381477355957, 2706.018753051758, 3416.826217651367, 2246.9429931640625, 3026.605697631836, 3464.750202178955, 1825.727237701416, 2801.5272521972656, 5808.767181396484, 5087.420768737793, 1082.8975448608398, 2245.4766235351562, 7158.7666664123535, 7002.55729675293, 2944.8764266967773, 539.1317138671875, 7958.601509094238, 1911.7941436767578, 4352.478107452393, 2637.1654090881348, 2806.990264892578, 1850.8513984680176, 1247.482006072998, 9211.335472106934, 2361.3474159240723, 895.9713706970215, 5303.860176086426, 3733.883327484131, 2197.9163665771484, 1588.0726356506348, 3500.7752685546875, 2435.2021484375, 628.7014389038086, 2296.279239654541, 2184.9853515625, 2083.3580741882324, 1335.9634895324707, 3963.0781784057617, 2899.5098762512207, 4914.357864379883, 2246.802761077881, 3407.469570159912, 10200.254959106445, 2936.034248352051, 3057.3683013916016, 4432.244812011719, 1499.1136627197266, 2412.772060394287, 16998.4658203125, 1222.432960510254, 2975.162399291992, 3744.8551025390625, 1723.5438041687012, 3338.3889770507812, 8333.026260375977, 2180.702323913574, 7360.323165893555, 2342.47127532959, 3012.4163360595703, 1713.2388801574707, 4452.356616973877, 2546.532958984375, 1119.9096984863281, 9567.37574005127, 2732.74080657959, 1985.6425476074219, 5413.723445892334, 6409.086101531982, 3159.0930976867676, 10597.580444335938, 7856.230026245117, 3030.301803588867, 508.3308334350586, 1130.6426849365234, 560.8151550292969, 6499.689836502075, 3793.4061279296875, 4256.346649169922, 1435.094524383545, 3436.6429290771484, 7131.150718688965, 1939.8910751342773, 4870.097923278809, 2749.231060028076, 3677.4323501586914, 2225.644199371338, 1872.5340118408203, 6396.497718811035, 1928.2928009033203, 2285.2704124450684, 6043.312381744385, 5050.693069458008, 2680.179470062256, 3157.696731567383, 2201.168643951416, 7821.744789123535, 1624.5124588012695, 856.8237457275391, 5496.354385375977, 3077.6835136413574, 2349.6719665527344, 748.7267456054688, 4073.105209350586, 2428.3954887390137, 1817.0574645996094, 5920.3290367126465, 4993.5459060668945, 1854.4925994873047, 2072.9463691711426, 1789.0212593078613, 520.4244689941406, 1150.474380493164, 8140.494827270508, 2520.2975730895996, 7516.091896057129, 6687.428070068359, 3503.385711669922, 8912.932121276855, 3002.554401397705, 5974.511394500732, 9364.592323303223, 5100.976051330566, 2289.1184997558594, 2059.6622200012207, 2165.2481384277344, 3346.9206199645996, 362.0802307128906, 5973.611869812012, 4004.9964752197266, 5101.291709899902, 2046.2641677856445, 10662.980934143066, 13573.969444274902, 11477.910469055176, 2886.705467224121, 1364.8636169433594, 848.6775016784668, 10670.783081054688, 16354.613876342773, 3897.8707885742188, 8372.294563293457, 3243.2444915771484, 2276.522689819336, 6379.23934173584, 6492.434658050537, 651.8412628173828, 2052.688877105713, 1723.7744064331055, 3153.0051822662354, 3060.687515258789, 4394.539451599121, 6675.55020904541, 2990.6583290100098, 1858.1193542480469, 2372.455764770508, 3093.902198791504, 2746.4090003967285, 14612.644729614258, 2811.2378158569336, 1891.8903579711914, 3800.3139877319336, 1307.2000579833984, 2141.088165283203, 591.614860534668, 6452.195220947266, 13003.247459411621, 2102.3277320861816, 3228.9734077453613, 8572.235948562622, 8412.161041259766, 2096.0284729003906, 2444.4545936584473, 4044.722969055176, 1657.6348762512207, 9289.812744140625, 3854.2752227783203, 9632.766010284424, 8112.124122619629, 5667.051368713379, 4630.630729675293, 2295.482307434082, 2409.1885261535645, 1655.4238395690918, 1127.933837890625, 14807.031356811523, 8921.268539428711, 2863.1365509033203, 2265.49560546875, 8788.589714050293, 1476.423225402832, 4070.2031860351562, 1800.3414134979248, 3197.3997325897217, 1943.660976409912, 2077.5389137268066, 2096.339225769043, 9350.587745666504, 3642.264778137207, 7266.568954467773, 962.6710166931152, 2215.44482421875, 9336.466674804688, 9867.654308319092, 2063.2134323120117, 1155.2154541015625, 1633.2371711730957, 1274.0163345336914, 4085.726833343506, 2180.4713287353516, 5976.453254699707, 1042.448974609375, 1682.9107627868652, 1226.0241394042969, 1304.459140777588, 3805.4078063964844, 2489.540771484375, 2844.7161712646484, 1944.237693786621, 2335.8497619628906, 2907.5292892456055, 716.8276863098145, 1952.089729309082, 1655.0312576293945, 1900.842945098877, 982.2731170654297, 3076.6930770874023, 2719.5298805236816, 1640.2900199890137, 3652.4767303466797, 2568.7037563323975, 2296.446060180664, 1185.803855895996, 10648.208488464355, 896.0819511413574, 9318.31330871582, 1521.3353424072266, 2228.1630363464355, 1538.315818786621, 6556.727935791016, 7087.24923324585, 12377.485675811768, 2071.650213241577, 2948.683120727539, 4243.414207458496, 2197.090202331543, 3039.7455863952637, 9418.738883972168, 2165.384708404541, 1924.1241264343262, 4896.777976989746, 3546.0012855529785, 1409.7500495910645, 3457.7429847717285, 2758.0788955688477, 3660.463691711426, 9888.186401367188, 3037.781753540039, 1957.9285621643066, 11523.31953239441, 4505.232009887695, 4324.730701446533, 3285.9085693359375, 3389.5893173217773, 2927.1558876037598, 3698.3954696655273, 2930.401054382324, 1347.898811340332, 724.7898063659668, 6288.717231750488, 1881.308235168457, 864.5178375244141, 846.0451698303223, 2973.7215824127197, 1763.1220169067383, 3111.827865600586, 1050.369068145752, 2650.686336517334, 2394.264097213745, 1944.7045269012451, 7607.827163696289, 1222.1859245300293, 1451.6677131652832, 1030.6132202148438, 1429.0567741394043, 3308.6086044311523, 2464.1118812561035, 10072.34750366211, 1034.6251754760742, 7482.228408813477, 1066.0309524536133, 959.1952171325684, 4410.124122619629, 2392.826141357422, 1161.6376838684082, 341.207218170166, 739.5136337280273, 2349.5172386169434, 13746.266540527344, 973.8420639038086, 2567.2644424438477, 1549.107894897461, 4146.492218017578, 9730.480346679688, 2039.6130332946777, 8450.917881011963, 3570.553268432617, 2259.4782371520996, 5512.657775878906, 758.4153060913086, 1741.408613204956, 1721.115463256836, 4830.559513092041, 2788.18025970459, 1690.1842632293701, 1238.9941520690918, 5758.51016998291, 5971.871505737305, 1632.3139839172363, 7910.1389083862305, 700.2363357543945, 2236.5371284484863, 1342.2797889709473, 7813.525993347168, 1998.3703994750977, 1229.536247253418, 1977.6525039672852, 2065.4499073028564, 1915.1072044372559, 4744.848937988281, 1176.9560623168945, 2187.934917449951, 7936.718505859375, 4493.700927734375, 767.6384811401367, 1424.3624649047852, 9585.970413208008, 1529.580795288086, 3395.3985290527344, 2098.9530029296875, 4508.4636154174805, 2823.0147705078125, 4002.6304321289062, 2292.141731262207, 7932.895881652832, 6955.771774291992, 6097.4412841796875, 2383.0974464416504, 7407.2888259887695, 924.2539596557617, 6392.713050842285, 2190.3555908203125, 3668.2593154907227, 1999.031623840332, 2681.2997398376465, 1575.500633239746, 2602.6978492736816, 1474.7320442199707, 1408.4949111938477, 12771.011840820312, 3006.210762023926, 3799.690055847168, 3966.533851623535, 1350.1649627685547, 1104.6913986206055, 1384.5937061309814, 2790.895519256592, 2531.0698852539062, 961.9472122192383, 1338.1433715820312, 1266.5471572875977, 1432.9936256408691, 3634.5124435424805, 6799.4597244262695, 1013.416955947876, 888.4494781494141, 1550.5837173461914, 11239.086921691895, 1407.6675720214844, 1472.4149780273438, 1505.742286682129, 1576.145492553711, 6508.929046630859, 1504.6887817382812, 4348.382579803467, 1106.9882469177246, 1164.5036392211914, 1683.6478691101074, 1440.480842590332, 1238.010108947754, 588.6526870727539, 833.9012413024902, 14227.477966308594, 2065.151798248291, 1636.5769882202148, 5234.489479064941, 2136.216194152832, 1771.744052886963, 513.9183578491211, 8162.743537902832, 952.0312366485596, 4880.722560882568]\n"
     ]
    }
   ],
   "source": [
    "# TODO: use a custom dataloader class and see if speed up\n",
    "\n",
    "env = gym.make(\n",
    "    \"LunarLander-v2\",\n",
    "    #render_mode=\"human\"\n",
    ")\n",
    "\n",
    "action_space_seed = np.random.seed(13)\n",
    "\n",
    "observation, info = env.reset(seed=13)\n",
    "\n",
    "episodes_total_rewards = []\n",
    "# for debug of state-value funtion\n",
    "episode_total_state_err = []\n",
    "\n",
    "# index i in the lists below corresponds to the timestep i of the current episode\n",
    "observations = []\n",
    "rewards = []\n",
    "# for debug of state-value funtion\n",
    "state_err = []\n",
    "\n",
    "\n",
    "\n",
    "for timestep in range(100000):\n",
    "    \n",
    "    # use policy gradient to get action probabilities; sample stochastically\n",
    "    action_weights = np.array(policy_model(torch.tensor(observation, device=device)).tolist())\n",
    "    action_array = np.random.multinomial(n=1, pvals=action_weights)\n",
    "    action = np.argmax(action_array)\n",
    "    \n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    observations.append(observation)\n",
    "    rewards.append(reward)\n",
    "    \n",
    "    # end of episode\n",
    "    if terminated or truncated:\n",
    "        ep_length = len(observations)\n",
    "        ep_total_reward = np.sum(np.array(rewards))\n",
    "        episodes_total_rewards.append(ep_total_reward)\n",
    "        returns = np.zeros(len(observations))\n",
    "        for timestep in reversed(range(ep_length)):\n",
    "\n",
    "            # calculate state's actual return by looking at reward + future rewards\n",
    "            terminal = timestep == len(rewards) - 1\n",
    "            returns[timestep] = rewards[timestep] + (gamma * returns[timestep+1]) if not terminal else rewards[timestep]\n",
    "            \n",
    "            pred_state_util = state_util_model(torch.tensor(observations[timestep], device=device))\n",
    "            actual_state_util = torch.tensor([returns[timestep]], device=device, dtype=torch.float32)\n",
    "            loss_state_utility = state_util_loss(pred_state_util, actual_state_util)\n",
    "            with torch.no_grad():\n",
    "                state_pred_err = np.abs(loss_state_utility.item())\n",
    "                state_err.append(state_pred_err)\n",
    "            \n",
    "            state_util_adam.zero_grad()\n",
    "            # print(returns[timestep])\n",
    "            # with torch.no_grad():\n",
    "                # _before_update = state_util_model(torch.tensor(observations[timestep], device=device, dtype=torch.float32))\n",
    "                # print(_before_update)\n",
    "            loss_state_utility.backward()\n",
    "            state_util_adam.step()\n",
    "            # with torch.no_grad():\n",
    "                # _after_update = state_util_model(torch.tensor(observations[timestep], device=device, dtype=torch.float32))\n",
    "                # print(_after_update)\n",
    "\n",
    "        episode_total_state_err.append(np.sum(np.array(state_err)))\n",
    "\n",
    "        observation, info = env.reset()\n",
    "        observations, rewards = [], []\n",
    "        state_err = []\n",
    "\n",
    "print(episode_total_state_err)\n",
    "print(f'The state val prediction error on the first quarter of episodes was: {np.sum(episode_total_state_err[:len(episode_total_state_err)//4])}')\n",
    "print(f'The state val prediction error on the second quarter of episodes was: {np.sum(episode_total_state_err[len(episode_total_state_err)//4:2 * len(episode_total_state_err)//4])}')\n",
    "print(f'The state val prediction error on the third quarter of episodes was: {np.sum(episode_total_state_err[2 * len(episode_total_state_err)//4:3 *len(episode_total_state_err)//4])}')\n",
    "print(f'The state val prediction error on the fourth quarter of episodes was: {np.sum(episode_total_state_err[3 *len(episode_total_state_err)//4:len(episode_total_state_err)])}')\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00c7148fe7d049885671e82bbf6f02dbbdff16ff92bf68e1f2741c72b6e7373b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
