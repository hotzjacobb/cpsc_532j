{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW Assignment 2\n",
    "\n",
    "Implement both PG and an evolutionary algorithm to solve the Open AI Gym Lunar Lander problem, and then apply it to my area of choice, which is chess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to do some setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.14.0.dev20221017\n",
      "Is MPS (Metal Performance Shader) built? True\n",
      "Is MPS available? True\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "# next few lines adapted from https://towardsdatascience.com/installing-pytorch-on-apple-m1-chip-with-gpu-acceleration-3351dc44d67c\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
    "print(f\"Is MPS (Metal Performance Shader) built? {torch.backends.mps.is_built()}\")\n",
    "print(f\"Is MPS available? {torch.backends.mps.is_available()}\")\n",
    "\n",
    "# Set the device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"gpu\" # ðŸ§®\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\" # ðŸ§ \n",
    "else:\n",
    "    device = \"cpu\" # ðŸ¥º\n",
    "    \n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to write the code for our Policy Gradient function with a baseline (REINFORCE). I'm going to use PyTorch as my neural network library.\n",
    "\n",
    "I'm going to start with a basic feed forward net for both the network that chooses the policy and the network that learns states' values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the policy network for choosing actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class PolicyChoice(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PolicyChoice, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.policy = nn.Sequential(\n",
    "            nn.Linear(8, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 4), # TODO: try reducing to one hidden layer if learning proves initially dificult\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 4),\n",
    "            nn.Softmax() # to have a nice interpretation as probabilities of choosing actions\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        probs = self.policy(x)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the network for approximating state utililities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the Lunar Lander environment now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"LunarLander-v2\",\n",
    "    continuous = False,\n",
    "    gravity = -10.0,\n",
    "    enable_wind = False,\n",
    "    wind_power = 15.0,\n",
    "    turbulence_power = 1.5,\n",
    ")\n",
    "\n",
    "for episode in range(10000):\n",
    "    action = policy(observation)  # User-defined policy function\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    if terminated or truncated:\n",
    "      observation, info = env.reset()\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00c7148fe7d049885671e82bbf6f02dbbdff16ff92bf68e1f2741c72b6e7373b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
